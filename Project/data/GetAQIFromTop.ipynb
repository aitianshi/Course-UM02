{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\"chinese_stations.html\", encoding=\"utf8\") as file:\n",
    "    soup = BeautifulSoup(file, 'html5lib')\n",
    "    cn_links = soup.find_all('a', href=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = []\n",
    "for link in cn_links:\n",
    "    stations.append(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('aqi.pkl', 'rb') as handle:\n",
    "    df_data = pickle.load(handle)\n",
    "with open('cities_done.pkl', 'rb') as handle:\n",
    "    done = pickle.load(handle)\n",
    "with open('cities_wait.pkl', 'rb') as handle:\n",
    "    wait = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import time\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "\n",
    "for station in stations:\n",
    "    \n",
    "    if station in done or station in wait:\n",
    "        continue\n",
    "\n",
    "    with open('cities_done.pkl', 'rb') as handle:\n",
    "        done = pickle.load(handle)\n",
    "    with open('cities_wait.pkl', 'rb') as handle:\n",
    "        wait = pickle.load(handle)\n",
    "        \n",
    "    print(station)\n",
    "        \n",
    "    resp = rq.request(\"GET\", station)\n",
    "    \n",
    "    if resp.status_code != 200: \n",
    "        print(\"STATUS_CODE ERROR : \", resp.status_code, resp.text)\n",
    "        continue\n",
    "    \n",
    "    soup = BeautifulSoup(resp.content, 'html5lib')\n",
    "    \n",
    "    info = soup.find(id = 'aqiwgtinfo')\n",
    "\n",
    "    if info is None or info.get_text() == \"no data\":\n",
    "        wait.append(station)\n",
    "        with open('cities_wait.pkl', 'wb') as handle:\n",
    "            pickle.dump(wait, handle)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        pm25 = soup.find(id = 'cur_pm25').get_text()\n",
    "    except AttributeError:\n",
    "        pm25 = None\n",
    "    \n",
    "    try:\n",
    "        co = soup.find(id = 'cur_co').get_text() \n",
    "    except AttributeError:\n",
    "        co = None\n",
    "    \n",
    "    try:\n",
    "        so2 = soup.find(id = 'cur_so2').get_text()\n",
    "    except AttributeError:\n",
    "        so2 = None\n",
    "        \n",
    "    try:\n",
    "        o3 = soup.find(id = 'cur_o3').get_text()\n",
    "    except AttributeError:\n",
    "        o3 = None\n",
    "        \n",
    "    try:\n",
    "        no2 = soup.find(id = 'cur_no2').get_text()\n",
    "    except AttributeError:\n",
    "        no2 = None\n",
    "        \n",
    "    try:\n",
    "        pm10 = soup.find(id = 'cur_pm10').get_text()\n",
    "    except AttributeError:\n",
    "        pm10 = None\n",
    "    \n",
    "    try:\n",
    "        temp = soup.find(id = 'cur_t').get_text()\n",
    "    except AttributeError:\n",
    "        temp = None\n",
    "        \n",
    "    name = soup.find(id = 'aqiwgttitle2').get_text().split(\"Real-time\")[0].strip()\n",
    "    aqi = soup.find(id = 'aqiwgtvalue').get_text()   \n",
    "\n",
    "    url = \"https://api.waqi.info/search/\"\n",
    "    qs = {\"token\":\"8b556369620cbd18f0fc03b37e3959bd970f0706\",\"keyword\": name}\n",
    "    resp_json = rq.request(\"GET\", url, params=qs)\n",
    "\n",
    "    if resp_json.status_code != 200: \n",
    "        print(\"STATUS_CODE ERROR : \", resp_json.status_code, resp_json.text)\n",
    "        continue\n",
    "        \n",
    "    json = resp_json.json()\n",
    "    \n",
    "    if json['data'] == []:\n",
    "        wait.append(station)\n",
    "        with open('cities_wait.pkl', 'wb') as handle:\n",
    "            pickle.dump(wait, handle)\n",
    "        continue\n",
    "    \n",
    "    coord = json['data'][0]['station']['geo']\n",
    "\n",
    "    geometry = Point(coord[0], coord[1])\n",
    "    \n",
    "    city = station.split(\"/\")[-3]\n",
    "    \n",
    "    df_data.loc[len(df_data)] = [city, name, aqi, pm25, pm10, no2, so2, o3, co, temp, coord[0], coord[1], geometry]\n",
    "    \n",
    "    done.append(station)\n",
    "    \n",
    "    df_data.to_pickle('aqi.pkl')\n",
    "    with open('cities_done.pkl', 'wb') as handle:\n",
    "        pickle.dump(done, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = pd.DataFrame(columns=('city','name','aqi','pm25','pm10','no2','so2','o3','co','temp','lat','long','geometry'))\n",
    "# wait = []\n",
    "#done = []\n",
    "#with open('cities_wait.pkl', 'wb') as handle:\n",
    "#    pickle.dump(wait, handle)\n",
    "#with open('cities_done.pkl', 'wb') as handle:\n",
    "#    pickle.dump(done, handle)\n",
    "#df_data.to_pickle('aqi.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
